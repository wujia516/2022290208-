# ----------------------------
# 基于大模型的情感语义分析
# ----------------------------

# 一、判断真假新闻 Prompt 模板
def generate_fact_check_prompt(title):
    return f"""You are a senior fact-checking expert. Based on the language, tone, and logic of the headline, decide whether it's real or fake.

Headline: {title}

Answer: Real / Fake

Reason: ...
"""

# 二、情感分析 Prompt 模板
def generate_sentiment_prompt(title):
    return f"""Read the news headline below and determine its sentiment as one of: Positive, Negative, or Neutral.

Headline: {title}

Sentiment: ...
Reason: ...
"""

# 三、结合情感信息判断真假新闻 Prompt
def generate_combined_prompt(title, sentiment):
    return f"""As a media analyst, determine whether the following headline is true or fake. Consider the tone, content, and emotional polarity.

Headline: {title}

Sentiment: {sentiment}

Answer: Real / Fake

Reason: ...
"""

# BERT + GPT 协同判断 Prompt 模板
def generate_bert_gpt_prompt(title, bert_result):
    return f"""You are an expert news analyst. The BERT model has preliminarily judged the following headline as {bert_result}.
Now, based on your own reasoning and the information from BERT, make a final judgment.

Headline: {title}

Answer: Real / Fake

Reason: ...
"""

# BERT + GPT + 情感语义分析 Prompt 模板
def generate_bert_gpt_sentiment_prompt(title, bert_result, sentiment):
    return f"""You are an expert news analyst. The BERT model preliminarily marked this headline as {bert_result}.
The sentiment analysis suggests the emotional tone is {sentiment}.
Based on this information and your own reasoning, determine whether the news is real or fake.

Headline: {title}

Sentiment: {sentiment}

Answer: Real / Fake

Reason: ...
"""

# 四、使用 GPT 和情感分析优化真假新闻判断的完整代码
def generate_optimized_prompt(title, sentiment, bert_result=None):
    if bert_result:
        return generate_bert_gpt_sentiment_prompt(title, bert_result, sentiment)
    else:
        return generate_combined_prompt(title, sentiment)

# 五、情感分析与真假新闻判断优化
# 定义一个处理新闻标题并判断情感的过程
def analyze_sentiment_and_fact(title):
    # 情感分析
    sentiment = analyze_sentiment(title)  # 模拟情感分析返回结果 (Positive/Negative/Neutral)
    
    # 假设我们使用 BERT 进行真假新闻的初步判断
    bert_result = bert_fact_check(title)  # 假设此函数返回 BERT 对新闻标题的初步判断
    
    # 使用优化的模板进行最终判断
    return generate_optimized_prompt(title, sentiment, bert_result)

# 模拟情感分析的函数
def analyze_sentiment(title):
    # 这里可以调用实际的情感分析模型
    # 例如，假设这个模型返回新闻的情感
    # 假设返回：'Positive', 'Negative', 'Neutral'
    return 'Neutral'  # 示例返回值，实际可以根据模型输出

# 模拟 BERT 模型进行初步的真假新闻判断
def bert_fact_check(title):
    # 这里可以调用实际的BERT模型进行初步的真假新闻判断
    # 假设返回 'Real' 或 'Fake' 基于模型的推理
    return 'Real'  # 示例返回值

# 六、应用示例
# 假设我们有一组新闻标题
headlines = [
    "NASA Launches New Mission to Mars",
    "Celebrity Found Dead, Suicide Note Discovered",
    "Community Organizes Charity for Homeless People",
    "Breaking News: Cure for Cancer Found!"
]

# 对每个标题应用分析函数
for headline in headlines:
    print(f"Processing headline: {headline}")
    result = analyze_sentiment_and_fact(headline)
    print(f"Generated prompt for {headline}: {result}")
    print("\n---\n")


# ----------------------------
# 基于大模型的Twitter主题分析
# ----------------------------
tweets = [
    "CDC Confirms New Breakthrough in Cancer Treatment",
    "Celebrity Found Dead in Apartment - Suicide Note Revealed",
    "NASA Launches Satellite to Monitor Global Warming",
    "Drinking Lemon Water Cures Diabetes, Experts Say",
    "Local Community Hosts Charity Drive for Homeless",
    "New Miracle Pill Helps You Lose 30 Pounds in a Week!",
    "President Signs Historic Climate Change Accord",
    "Bill Gates: Aliens Are Among Us and Watching Closely",
    "Community Volunteers Organize Free Health Clinic",
    "Study Shows New Drug Can Cure Rare Disease"
]

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]
    return tokens

processed_tweets = [preprocess(tweet) for tweet in tweets]

from gensim import corpora, models

dictionary = corpora.Dictionary(processed_tweets)
corpus = [dictionary.doc2bow(text) for text in processed_tweets]

lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, passes=10)

import pyLDAvis
import pyLDAvis.gensim_models

pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)

from wordcloud import WordCloud
import matplotlib.pyplot as plt

for t in range(3):
    plt.figure(figsize=(8, 6))
    plt.imshow(WordCloud().fit_words(dict(lda_model.show_topic(t, 10))))
    plt.axis("off")
    plt.title(f"Topic {t}")
    plt.show()

import seaborn as sns
import pandas as pd

topic_dist = [lda_model.get_document_topics(doc, minimum_probability=0) for doc in corpus]
topic_df = pd.DataFrame([[prob for _, prob in doc] for doc in topic_dist])

sns.heatmap(topic_df, annot=True, cmap="YlGnBu")
plt.title("Document-Topic Distribution")
plt.xlabel("Topic")
plt.ylabel("Document")
plt.show()

from textblob import TextBlob

def sentiment_analysis(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    if polarity > 0:
        return "Positive"
    elif polarity < 0:
        return "Negative"
    else:
        return "Neutral"

sentiments = [sentiment_analysis(tweet) for tweet in tweets]

topic_with_sentiment = []
for i, tweet in enumerate(tweets):
    doc_topic_dist = lda_model.get_document_topics(corpus[i])
    sentiment = sentiments[i]
    tweet_topic_labels = [lda_model.print_topic(topic_id) for topic_id, _ in doc_topic_dist]
    
    tweet_analysis = {
        'Tweet': tweet,
        'Topics': tweet_topic_labels,
        'Sentiment': sentiment
    }
    
    topic_with_sentiment.append(tweet_analysis)

for analysis in topic_with_sentiment:
    print(f"Tweet: {analysis['Tweet']}")
    print(f"Topics: {analysis['Topics']}")
    print(f"Sentiment: {analysis['Sentiment']}")
    print("\n---\n")

topic_sentiment_dist = []

for i, analysis in enumerate(topic_with_sentiment):
    topic_sentiment_dist.append({
        'Tweet': analysis['Tweet'],
        'Sentiment': analysis['Sentiment'],
        'Topic Distribution': [topic_prob for _, topic_prob in lda_model.get_document_topics(corpus[i])]
    })

topic_sentiment_df = pd.DataFrame(topic_sentiment_dist)
sns.heatmap(topic_sentiment_df.drop('Tweet', axis=1), annot=True, cmap="coolwarm", xticklabels=range(1, 4), yticklabels=topic_sentiment_df['Sentiment'])
plt.title("Topic Sentiment Distribution")
plt.xlabel("Topic")
plt.ylabel("Sentiment")
plt.show()

# ----------------------------
# 基于多模态情感语义分析与预测模型
# ----------------------------

import torch
import torch.nn as nn
import torch.optim as optim
from transformers import BertTokenizer, BertModel
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class BERTTextModel(nn.Module):
    def __init__(self, pretrained_model_name="bert-base-uncased"):
        super(BERTTextModel, self).__init__()
        self.bert = BertModel.from_pretrained(pretrained_model_name)
        self.fc = nn.Linear(self.bert.config.hidden_size, 256)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids, attention_mask=attention_mask)
        hidden_states = outputs[1]
        x = self.fc(hidden_states)
        return x

class ImageFeatureExtractor(nn.Module):
    def __init__(self):
        super(ImageFeatureExtractor, self).__init__()
        self.resnet = models.resnet50(pretrained=True)
        self.resnet.fc = nn.Identity()
        self.fc = nn.Linear(2048, 256)

    def forward(self, x):
        x = self.resnet(x)
        x = self.fc(x)
        return x

class CrossModalAttention(nn.Module):
    def __init__(self, input_size=256):
        super(CrossModalAttention, self).__init__()
        self.attn_fc_text = nn.Linear(input_size, input_size)
        self.attn_fc_image = nn.Linear(input_size, input_size)

    def forward(self, text_features, image_features):
        text_weighted = torch.softmax(self.attn_fc_text(text_features), dim=-1)
        image_weighted = torch.softmax(self.attn_fc_image(image_features), dim=-1)

        fused_features = text_weighted * text_features + image_weighted * image_features
        return fused_features

class MultiModalPredictor(nn.Module):
    def __init__(self):
        super(MultiModalPredictor, self).__init__()
        self.text_model = BERTTextModel()
        self.image_model = ImageFeatureExtractor()
        self.attn_module = CrossModalAttention()
        self.fc = nn.Linear(256, 2)

    def forward(self, input_ids, attention_mask, image_tensor):
        text_features = self.text_model(input_ids, attention_mask)
        image_features = self.image_model(image_tensor)

        fused_features = self.attn_module(text_features, image_features)

        output = self.fc(fused_features)
        return output

class MultiModalDataset(Dataset):
    def __init__(self, texts, images, labels, tokenizer, transform=None):
        self.texts = texts
        self.images = images
        self.labels = labels
        self.tokenizer = tokenizer
        self.transform = transform

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        image = Image.open(self.images[idx])
        label = self.labels[idx]

        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=128, return_tensors='pt')
        input_ids = encoding['input_ids'].squeeze(0)
        attention_mask = encoding['attention_mask'].squeeze(0)

        if self.transform:
            image = self.transform(image)

        return input_ids, attention_mask, image, label

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

texts = ["Example text 1", "Example text 2", "Example text 3"]
images = ["path_to_image1.jpg", "path_to_image2.jpg", "path_to_image3.jpg"]
labels = [0, 1, 0]

train_texts, test_texts, train_images, test_images, train_labels, test_labels = train_test_split(texts, images, labels, test_size=0.2, random_state=42)

train_dataset = MultiModalDataset(train_texts, train_images, train_labels, tokenizer, transform)
test_dataset = MultiModalDataset(test_texts, test_images, test_labels, tokenizer, transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

def train_model(model, train_loader, criterion, optimizer):
    model.train()
    running_loss = 0.0
    for input_ids, attention_mask, image, labels in train_loader:
        input_ids, attention_mask, image, labels = input_ids.to(device), attention_mask.to(device), image.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask, image)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    return running_loss / len(train_loader)

def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for input_ids, attention_mask, image, labels in test_loader:
            input_ids, attention_mask, image, labels = input_ids.to(device), attention_mask.to(device), image.to(device), labels.to(device)

            outputs = model(input_ids, attention_mask, image)
            _, preds = torch.max(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    return accuracy

model = MultiModalPredictor().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-5)

num_epochs = 10
for epoch in range(num_epochs):
    train_loss = train_model(model, train_loader, criterion, optimizer)
    accuracy = evaluate_model(model, test_loader)
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.4f}")

torch.save(model.state_dict(), "multimodal_model.pth")

